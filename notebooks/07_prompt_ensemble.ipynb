{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import imodelsx.process_results\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import viz\n",
    "import transformers\n",
    "import sys\n",
    "import tprompt.utils\n",
    "from os.path import join\n",
    "import datasets\n",
    "from typing import Dict, List\n",
    "from sklearn.tree import plot_tree\n",
    "import imodelsx.util\n",
    "import imodelsx.metrics\n",
    "import numpy as np\n",
    "import tprompt.utils\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch.cuda\n",
    "import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "sys.path.append('../experiments/')\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import sys\n",
    "from os.path import join\n",
    "import datasets\n",
    "from typing import Dict, List\n",
    "from dict_hash import sha256\n",
    "import joblib\n",
    "import random\n",
    "import numpy as np\n",
    "import sklearn.tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import imodelsx.treeprompt.stump\n",
    "import ensembling\n",
    "from ensembling import PromptHooker, modify_activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load prompt vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "checkpoint = 'gpt2'\n",
    "prompts = [\n",
    "    \" This review of a movie is\",\n",
    "    # \" This review of a movie is good\",\n",
    "    # \" Positive or Negative? The movie was\",\n",
    "    \" The sentiment of the movie was\",\n",
    "    # \" The plot of the movie was really\",\n",
    "    \" The acting in the movie was\",\n",
    "]\n",
    "# note: also requires specifying the layer for the hook below\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUTS_ALL = {}\n",
    "PROMPT_NUM_GLOBAL = 0\n",
    "\n",
    "\n",
    "def store_activations(module, inputs, outputs):\n",
    "    global OUTPUTS_ALL\n",
    "    global PROMPT_NUM_GLOBAL\n",
    "    OUTPUTS_ALL[PROMPT_NUM_GLOBAL] = outputs.detach().cpu()\n",
    "    PROMPT_NUM_GLOBAL += 1\n",
    "    return outputs * 3  # * 0.01\n",
    "\n",
    "\n",
    "hook = model.transformer.drop.register_forward_hook(store_activations)\n",
    "for i, prompt in enumerate(prompts):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    # hook = model.transformer.h[3].register_forward_hook(change_activations)\n",
    "    logits_modified = model(**inputs).logits\n",
    "\n",
    "hook.remove()\n",
    "assert len(OUTPUTS_ALL) == len(prompts)\n",
    "\n",
    "# most_probable_tokens = torch.topk(logits_modified, k=10, dim=-1)\n",
    "# print('\\n'.join([tokenizer.decode(x)\n",
    "#   for x in most_probable_tokens.indices[0, -1]]))\n",
    "# logits_orig = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(prompts)):\n",
    "    print(i, prompts[i], OUTPUTS_ALL[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [len(x) for x in tokenizer(prompts)['input_ids']]\n",
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg = torch.concat(tuple(OUTPUTS_ALL.values())).mean(axis=0).unsqueeze(0)\n",
    "vals = list(OUTPUTS_ALL.values())\n",
    "\n",
    "# add left zero padding eac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_train = datasets.load_dataset('rotten_tomatoes')['train']\n",
    "dset_train = dset_train.select(np.random.choice(\n",
    "    len(dset_train), size=200, replace=False))\n",
    "# dset_val = datasets.load_dataset('rotten_tomatoes')['validation']\n",
    "# dset_val = dset_val.select(np.random.choice(\n",
    "#     len(dset_val), size=100, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 0:  This review of a movie is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              0.79it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1:  The sentiment of the movie was\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              1.11it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 2:  The acting in the movie was\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              1.11it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  This review of a movie is -> 0.435\n",
      "1  The sentiment of the movie was -> 0.48\n",
      "2  The acting in the movie was -> 0.47\n",
      "------------------------\n",
      "Prompt 0:  This review of a movie is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged -> 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "verbalizer = {0: \" Negative.\", 1: \" Positive.\"}\n",
    "\n",
    "m = PromptHooker(\n",
    "    checkpoint=checkpoint,\n",
    "    prompts=prompts,\n",
    "    verbalizer=verbalizer,\n",
    "    cache_prompt_features_dir=None,\n",
    "    random_state=42,\n",
    "    hook_weights=None,\n",
    "    prompt_at_start_or_end='end',\n",
    ")\n",
    "m.fit(dset_train[\"text\"], dset_train[\"label\"])\n",
    "for i, prompt in enumerate(prompts):\n",
    "    print(i, prompt, '->', m.prompt_accs_[i])\n",
    "\n",
    "\n",
    "print('------------------------')\n",
    "m = PromptHooker(\n",
    "    checkpoint=checkpoint,\n",
    "    prompts=[prompts[0]],\n",
    "    verbalizer=verbalizer,\n",
    "    cache_prompt_features_dir=None,\n",
    "    random_state=42,\n",
    "    hook_weights=avg,\n",
    "    prompt_at_start_or_end='end',\n",
    ")\n",
    "m.fit(dset_train[\"text\"], dset_train[\"label\"])\n",
    "print('Averaged ->', m.prompt_accs_[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
