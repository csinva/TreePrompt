{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:08<00:00, 12.85it/s]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import imodelsx.process_results\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import viz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy import stats\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from scipy.sparse import issparse\n",
    "import sys\n",
    "sys.path.append('../experiments/')\n",
    "results_dir = '/home/chansingh/mntv1/tree-prompt/dummy_runs/'\n",
    "\n",
    "r = imodelsx.process_results.get_results_df(results_dir, results_fname='params.json')\n",
    "experiment_filename = '../experiments/01_fit.py'\n",
    "r = imodelsx.process_results.fill_missing_args_with_default(r, experiment_filename)\n",
    "# imodelsx.process_results.delete_runs_in_dataframe(\n",
    "    # r[(~r.dataset_name.str.startswith('knnp')) & (r.prompt_source == 'data_demonstrations')], actually_delete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset_name          prompt_source      \n",
       "emotion               manual                 8\n",
       "financial_phrasebank  manual                 8\n",
       "imdb                  manual                 8\n",
       "knnp__agnews          data_demonstrations    8\n",
       "knnp__cb              data_demonstrations    8\n",
       "knnp__cr              data_demonstrations    8\n",
       "knnp__dbpedia         data_demonstrations    8\n",
       "knnp__mpqa            data_demonstrations    8\n",
       "knnp__rte             data_demonstrations    8\n",
       "knnp__subj            data_demonstrations    8\n",
       "knnp__trec            data_demonstrations    8\n",
       "rotten_tomatoes       manual                 8\n",
       "sst2                  manual                 8\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):\n",
    "    display(r.groupby(['dataset_name', 'prompt_source']).size())\n",
    "    # display(r.groupby(['dataset_name', 'prompt_source'])\n",
    "    # ['checkpoint'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/104 [00:00<01:27,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.376\n",
      "emotion meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/104 [00:01<01:08,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.354\n",
      "emotion llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/104 [00:02<01:14,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.354\n",
      "emotion gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/104 [00:02<01:15,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.375\n",
      "emotion gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 5/104 [00:03<01:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.393\n",
      "emotion EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/104 [00:04<01:10,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.333\n",
      "emotion meta-llama/Llama-2-13b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/104 [00:04<00:56,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.344\n",
      "emotion gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/104 [00:04<00:45,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.394\n",
      "financial_phrasebank meta-llama/Llama-2-13b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 10/104 [00:05<00:30,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.248\n",
      "financial_phrasebank gpt2-medium\n",
      "acc improvement 0.197\n",
      "financial_phrasebank gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/104 [00:05<00:22,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.22\n",
      "financial_phrasebank llama_7b\n",
      "acc improvement 0.225\n",
      "financial_phrasebank gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 14/104 [00:05<00:18,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.101\n",
      "financial_phrasebank meta-llama/Llama-2-7b-hf\n",
      "acc improvement 0.239\n",
      "financial_phrasebank EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 16/104 [00:06<00:15,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.232\n",
      "financial_phrasebank gpt2-large\n",
      "acc improvement 0.225\n",
      "imdb meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 17/104 [00:08<01:07,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.359\n",
      "imdb EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 18/104 [00:10<01:41,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.335\n",
      "imdb gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 19/104 [00:12<02:05,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.366\n",
      "imdb llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 20/104 [00:14<02:03,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.382\n",
      "imdb gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 21/104 [00:15<02:03,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.407\n",
      "imdb gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 22/104 [00:17<02:01,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.399\n",
      "imdb meta-llama/Llama-2-13b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 23/104 [00:18<01:59,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.371\n",
      "imdb gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 24/104 [00:20<01:57,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.349\n",
      "knnp__agnews llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 25/104 [00:20<01:31,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.453\n",
      "knnp__agnews meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 26/104 [00:20<01:14,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.566\n",
      "knnp__agnews gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 27/104 [00:21<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.367\n",
      "knnp__agnews EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 28/104 [00:21<00:50,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.52\n",
      "knnp__agnews meta-llama/Llama-2-13b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 29/104 [00:22<00:43,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.539\n",
      "knnp__agnews gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 30/104 [00:22<00:38,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.504\n",
      "knnp__agnews gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 31/104 [00:22<00:34,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.477\n",
      "knnp__agnews gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 32/104 [00:23<00:34,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.43\n",
      "knnp__cb meta-llama/Llama-2-13b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 33/104 [00:23<00:31,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.232\n",
      "knnp__cb gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 34/104 [00:24<00:29,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.036\n",
      "knnp__cb gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 35/104 [00:24<00:28,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.196\n",
      "knnp__cb meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 36/104 [00:25<00:34,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.196\n",
      "knnp__cb gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 37/104 [00:25<00:31,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.196\n",
      "knnp__cb llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 38/104 [00:25<00:28,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.0\n",
      "knnp__cb gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 39/104 [00:26<00:25,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.036\n",
      "knnp__cb EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 41/104 [00:26<00:20,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.268\n",
      "knnp__cr gpt2\n",
      "acc improvement 0.246\n",
      "knnp__cr gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 43/104 [00:27<00:14,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.168\n",
      "knnp__cr meta-llama/Llama-2-13b-hf\n",
      "acc improvement 0.18\n",
      "knnp__cr meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 45/104 [00:27<00:11,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.355\n",
      "knnp__cr gpt2-large\n",
      "acc improvement 0.352\n",
      "knnp__cr gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 47/104 [00:27<00:10,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.281\n",
      "knnp__cr EleutherAI/gpt-j-6B\n",
      "acc improvement 0.168\n",
      "knnp__cr llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 48/104 [00:27<00:10,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.301\n",
      "knnp__dbpedia llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 49/104 [00:29<00:26,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.098\n",
      "knnp__dbpedia gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 50/104 [00:30<00:43,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.152\n",
      "knnp__dbpedia gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 51/104 [00:32<00:53,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.098\n",
      "knnp__dbpedia gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 52/104 [00:32<00:50,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.172\n",
      "knnp__dbpedia EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 53/104 [00:34<00:52,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.141\n",
      "knnp__dbpedia gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 54/104 [00:35<00:51,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.133\n",
      "knnp__dbpedia meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 55/104 [00:36<00:53,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.148\n",
      "knnp__dbpedia meta-llama/Llama-2-13b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 56/104 [00:37<00:55,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.141\n",
      "knnp__mpqa gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 58/104 [00:38<00:29,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.215\n",
      "knnp__mpqa gpt2-xl\n",
      "acc improvement 0.203\n",
      "knnp__mpqa meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 60/104 [00:38<00:17,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.312\n",
      "knnp__mpqa meta-llama/Llama-2-13b-hf\n",
      "acc improvement 0.0\n",
      "knnp__mpqa gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 62/104 [00:38<00:11,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.133\n",
      "knnp__mpqa EleutherAI/gpt-j-6B\n",
      "acc improvement 0.203\n",
      "knnp__mpqa gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 64/104 [00:38<00:08,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.117\n",
      "knnp__mpqa llama_7b\n",
      "acc improvement -0.004\n",
      "knnp__rte gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 65/104 [00:39<00:08,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.012\n",
      "knnp__rte meta-llama/Llama-2-7b-hf\n",
      "acc improvement 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 67/104 [00:39<00:07,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knnp__rte meta-llama/Llama-2-13b-hf\n",
      "acc improvement 0.152\n",
      "knnp__rte gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 69/104 [00:40<00:07,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.047\n",
      "knnp__rte gpt2-medium\n",
      "acc improvement 0.023\n",
      "knnp__rte llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 71/104 [00:40<00:06,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement -0.02\n",
      "knnp__rte gpt2-xl\n",
      "acc improvement -0.027\n",
      "knnp__rte EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 73/104 [00:41<00:08,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.086\n",
      "knnp__subj gpt2\n",
      "acc improvement 0.039\n",
      "knnp__subj EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 74/104 [00:41<00:07,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.434\n",
      "knnp__subj gpt2-large\n",
      "acc improvement 0.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 76/104 [00:41<00:05,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knnp__subj llama_7b\n",
      "acc improvement 0.039\n",
      "knnp__subj meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 78/104 [00:42<00:04,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.387\n",
      "knnp__subj gpt2-medium\n",
      "acc improvement 0.324\n",
      "knnp__subj gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 80/104 [00:42<00:04,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.336\n",
      "knnp__subj meta-llama/Llama-2-13b-hf\n",
      "acc improvement 0.023\n",
      "knnp__trec gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 82/104 [00:42<00:03,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.312\n",
      "knnp__trec gpt2\n",
      "acc improvement 0.223\n",
      "knnp__trec llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 84/104 [00:43<00:03,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.312\n",
      "knnp__trec EleutherAI/gpt-j-6B\n",
      "acc improvement 0.34\n",
      "knnp__trec meta-llama/Llama-2-13b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 85/104 [00:43<00:03,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement -0.098\n",
      "knnp__trec gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 86/104 [00:43<00:03,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.211\n",
      "knnp__trec gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 88/104 [00:43<00:03,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.297\n",
      "knnp__trec meta-llama/Llama-2-7b-hf\n",
      "acc improvement 0.434\n",
      "rotten_tomatoes gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 89/104 [00:44<00:04,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.336\n",
      "rotten_tomatoes gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 90/104 [00:44<00:04,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.337\n",
      "rotten_tomatoes gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 91/104 [00:45<00:04,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.265\n",
      "rotten_tomatoes gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 92/104 [00:45<00:04,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.29\n",
      "rotten_tomatoes EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 93/104 [00:46<00:04,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.287\n",
      "rotten_tomatoes meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 94/104 [00:46<00:04,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.356\n",
      "rotten_tomatoes llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 95/104 [00:46<00:03,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.28\n",
      "rotten_tomatoes meta-llama/Llama-2-13b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 96/104 [00:47<00:03,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.362\n",
      "sst2 gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 97/104 [00:49<00:06,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.227\n",
      "sst2 meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 98/104 [00:50<00:06,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.352\n",
      "sst2 meta-llama/Llama-2-13b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 99/104 [00:52<00:06,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.366\n",
      "sst2 gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 100/104 [00:55<00:06,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.384\n",
      "sst2 llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 101/104 [00:56<00:04,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.334\n",
      "sst2 gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 102/104 [00:59<00:03,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.385\n",
      "sst2 gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 103/104 [01:00<00:01,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.267\n",
      "sst2 EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [01:02<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PROCESSED_DIR = os.path.expanduser('~/cost-optimal-tree/data_processed/')\n",
    "r = r.sort_values(by=['dataset_name']).reset_index().drop(columns=['index'])\n",
    "for k in ['n_train', 'n_test', 'n_prompts', 'n_outputs']:\n",
    "    r[k] = np.nan\n",
    "for i in tqdm(range(r.shape[0])):\n",
    "    args = r.iloc[i]\n",
    "    print(args.dataset_name, args.checkpoint)\n",
    "    run = joblib.load(join(args.save_dir_unique, 'cached_dset.pkl'))\n",
    "\n",
    "    out_dir = join(DATA_PROCESSED_DIR, args.dataset_name)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    X_train = run['X_train']\n",
    "    X_test = run['X_test']\n",
    "    y_train = run['y_train']\n",
    "    y_test = run['y_test']\n",
    "    feature_names = run['feature_names']\n",
    "\n",
    "    # run data checks\n",
    "    # check that X only contains ones and zeros\n",
    "    if issparse(X_train):\n",
    "        X_train = X_train.toarray()\n",
    "        X_test = X_test.toarray()\n",
    "    assert np.all(np.isin(X_train, [0, 1]))\n",
    "    assert np.all(np.isin(X_test, [0, 1]))\n",
    "\n",
    "    # remove any cols that are all the same value\n",
    "    idxs_constant = np.where(np.all(X_train == X_train[0, :], axis=0))[0]\n",
    "    # print(f'removing {idxs_constant.size} constant cols')\n",
    "    # print('unique', np.unique(X_train))\n",
    "    X_train = np.delete(X_train, idxs_constant, axis=1)\n",
    "    X_test = np.delete(X_test, idxs_constant, axis=1)\n",
    "    feature_names = np.delete(feature_names, idxs_constant)\n",
    "\n",
    "    # fit simple sklearn classifier\n",
    "    clf = DecisionTreeClassifier(random_state=42, max_depth=3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    acc_baseline = np.unique(y_test, return_counts=True)[1][0] / y_test.size\n",
    "    acc_improvement = acc - acc_baseline\n",
    "    print('acc improvement', acc_improvement.round(3))\n",
    "    # assert acc > acc_baseline\n",
    "\n",
    "    # export data\n",
    "    X_train = X_train.astype(bool)\n",
    "    X_test = X_test.astype(bool)\n",
    "\n",
    "    joblib.dump(\n",
    "        {\n",
    "            'X_train': X_train,\n",
    "            'X_test': X_test,\n",
    "            # 'y_train': y_train,\n",
    "            # 'y_test': y_test,\n",
    "            'feature_names': feature_names,\n",
    "            'verbalizer': args['verbalizer'],\n",
    "            'acc_improvement': acc_improvement,\n",
    "            'acc': acc,\n",
    "        },\n",
    "        join(out_dir, imodelsx.viz.CHECKPOINTS_RENAME_DICT.get(\n",
    "            args.checkpoint) + '_features.pkl')\n",
    "    )\n",
    "    joblib.dump({\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "    }, join(out_dir, 'labels.pkl'))\n",
    "\n",
    "    r.loc[i, 'n_train'] = X_train.shape[0]\n",
    "    r.loc[i, 'n_test'] = X_test.shape[0]\n",
    "    r.loc[i, 'n_prompts'] = X_train.shape[1]\n",
    "    r.loc[i, 'n_outputs'] = np.unique(y_train).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n_prompts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_name</th>\n",
       "      <th>prompt_source</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_outputs</th>\n",
       "      <th>checkpoint</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">emotion</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">manual</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">10028.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">1254.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-hf</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">financial_phrasebank</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">manual</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">871.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">436.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-hf</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">imdb</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">manual</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">25000.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">25000.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-hf</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">knnp__agnews</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">4.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-hf</th>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">knnp__cb</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">56.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">3.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-hf</th>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">knnp__cr</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-hf</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">knnp__dbpedia</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">14.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>439.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-hf</th>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">knnp__mpqa</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-hf</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">knnp__rte</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-hf</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">knnp__subj</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-hf</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">knnp__trec</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">6.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-hf</th>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">rotten_tomatoes</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">manual</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">8530.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">1066.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-hf</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">sst2</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">manual</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">67349.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">872.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-hf</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              n_prompts\n",
       "dataset_name         prompt_source       n_train n_test  n_outputs checkpoint                          \n",
       "emotion              manual              10028.0 1254.0  2.0       EleutherAI/gpt-j-6B             32.0\n",
       "                                                                   gpt2                            32.0\n",
       "                                                                   gpt2-large                      32.0\n",
       "                                                                   gpt2-medium                     32.0\n",
       "                                                                   gpt2-xl                         32.0\n",
       "                                                                   llama_7b                        32.0\n",
       "                                                                   meta-llama/Llama-2-13b-hf       32.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf        32.0\n",
       "financial_phrasebank manual              871.0   436.0   2.0       EleutherAI/gpt-j-6B             40.0\n",
       "                                                                   gpt2                            35.0\n",
       "                                                                   gpt2-large                      38.0\n",
       "                                                                   gpt2-medium                     40.0\n",
       "                                                                   gpt2-xl                         40.0\n",
       "                                                                   llama_7b                        40.0\n",
       "                                                                   meta-llama/Llama-2-13b-hf       40.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf        40.0\n",
       "imdb                 manual              25000.0 25000.0 2.0       EleutherAI/gpt-j-6B             94.0\n",
       "                                                                   gpt2                            94.0\n",
       "                                                                   gpt2-large                      94.0\n",
       "                                                                   gpt2-medium                     90.0\n",
       "                                                                   gpt2-xl                         94.0\n",
       "                                                                   llama_7b                        94.0\n",
       "                                                                   meta-llama/Llama-2-13b-hf       94.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf        94.0\n",
       "knnp__agnews         data_demonstrations 100.0   256.0   4.0       EleutherAI/gpt-j-6B            160.0\n",
       "                                                                   gpt2                           150.0\n",
       "                                                                   gpt2-large                     151.0\n",
       "                                                                   gpt2-medium                    143.0\n",
       "                                                                   gpt2-xl                        154.0\n",
       "                                                                   llama_7b                       160.0\n",
       "                                                                   meta-llama/Llama-2-13b-hf      160.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf       160.0\n",
       "knnp__cb             data_demonstrations 100.0   56.0    3.0       EleutherAI/gpt-j-6B            120.0\n",
       "                                                                   gpt2                           109.0\n",
       "                                                                   gpt2-large                     119.0\n",
       "                                                                   gpt2-medium                    118.0\n",
       "                                                                   gpt2-xl                        117.0\n",
       "                                                                   llama_7b                       120.0\n",
       "                                                                   meta-llama/Llama-2-13b-hf      120.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf       116.0\n",
       "knnp__cr             data_demonstrations 100.0   256.0   2.0       EleutherAI/gpt-j-6B             40.0\n",
       "                                                                   gpt2                            38.0\n",
       "                                                                   gpt2-large                      40.0\n",
       "                                                                   gpt2-medium                     40.0\n",
       "                                                                   gpt2-xl                         40.0\n",
       "                                                                   llama_7b                        40.0\n",
       "                                                                   meta-llama/Llama-2-13b-hf       40.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf        40.0\n",
       "knnp__dbpedia        data_demonstrations 100.0   256.0   14.0      EleutherAI/gpt-j-6B            558.0\n",
       "                                                                   gpt2                           439.0\n",
       "                                                                   gpt2-large                     402.0\n",
       "                                                                   gpt2-medium                    458.0\n",
       "                                                                   gpt2-xl                        519.0\n",
       "                                                                   llama_7b                       560.0\n",
       "                                                                   meta-llama/Llama-2-13b-hf      560.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf       559.0\n",
       "knnp__mpqa           data_demonstrations 100.0   256.0   2.0       EleutherAI/gpt-j-6B             40.0\n",
       "                                                                   gpt2                            40.0\n",
       "                                                                   gpt2-large                      40.0\n",
       "                                                                   gpt2-medium                     40.0\n",
       "                                                                   gpt2-xl                         40.0\n",
       "                                                                   llama_7b                        40.0\n",
       "                                                                   meta-llama/Llama-2-13b-hf       40.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf        40.0\n",
       "knnp__rte            data_demonstrations 100.0   256.0   2.0       EleutherAI/gpt-j-6B             40.0\n",
       "                                                                   gpt2                            36.0\n",
       "                                                                   gpt2-large                      40.0\n",
       "                                                                   gpt2-medium                     40.0\n",
       "                                                                   gpt2-xl                         40.0\n",
       "                                                                   llama_7b                        40.0\n",
       "                                                                   meta-llama/Llama-2-13b-hf       40.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf        40.0\n",
       "knnp__subj           data_demonstrations 100.0   256.0   2.0       EleutherAI/gpt-j-6B             40.0\n",
       "                                                                   gpt2                            24.0\n",
       "                                                                   gpt2-large                      40.0\n",
       "                                                                   gpt2-medium                     39.0\n",
       "                                                                   gpt2-xl                         40.0\n",
       "                                                                   llama_7b                        40.0\n",
       "                                                                   meta-llama/Llama-2-13b-hf       40.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf        37.0\n",
       "knnp__trec           data_demonstrations 100.0   256.0   6.0       EleutherAI/gpt-j-6B            240.0\n",
       "                                                                   gpt2                           235.0\n",
       "                                                                   gpt2-large                     240.0\n",
       "                                                                   gpt2-medium                    240.0\n",
       "                                                                   gpt2-xl                        240.0\n",
       "                                                                   llama_7b                       178.0\n",
       "                                                                   meta-llama/Llama-2-13b-hf      152.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf       240.0\n",
       "rotten_tomatoes      manual              8530.0  1066.0  2.0       EleutherAI/gpt-j-6B             87.0\n",
       "                                                                   gpt2                            85.0\n",
       "                                                                   gpt2-large                      87.0\n",
       "                                                                   gpt2-medium                     81.0\n",
       "                                                                   gpt2-xl                         86.0\n",
       "                                                                   llama_7b                        94.0\n",
       "                                                                   meta-llama/Llama-2-13b-hf       94.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf        94.0\n",
       "sst2                 manual              67349.0 872.0   2.0       EleutherAI/gpt-j-6B             89.0\n",
       "                                                                   gpt2                            87.0\n",
       "                                                                   gpt2-large                      88.0\n",
       "                                                                   gpt2-medium                     82.0\n",
       "                                                                   gpt2-xl                         91.0\n",
       "                                                                   llama_7b                        94.0\n",
       "                                                                   meta-llama/Llama-2-13b-hf       94.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf        94.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):\n",
    "    metadata = r.groupby(['dataset_name', 'prompt_source', 'n_train',\n",
    "                          'n_test', 'n_outputs', 'checkpoint'])[['n_prompts']].sum()\n",
    "    display(metadata)\n",
    "metadata.to_pickle(join(DATA_PROCESSED_DIR, 'metadata.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
