{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:08<00:00, 12.61it/s]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import imodelsx.process_results\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import viz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy import stats\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from scipy.sparse import issparse\n",
    "import sys\n",
    "sys.path.append('../experiments/')\n",
    "results_dir = '/home/chansingh/mntv1/tree-prompt/dummy_runs/'\n",
    "\n",
    "r = imodelsx.process_results.get_results_df(results_dir, results_fname='params.json')\n",
    "experiment_filename = '../experiments/01_fit.py'\n",
    "r = imodelsx.process_results.fill_missing_args_with_default(r, experiment_filename)\n",
    "# imodelsx.process_results.delete_runs_in_dataframe(\n",
    "    # r[(~r.dataset_name.str.startswith('knnp')) & (r.prompt_source == 'data_demonstrations')], actually_delete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset_name          prompt_source      \n",
       "emotion               manual                 7\n",
       "financial_phrasebank  manual                 7\n",
       "imdb                  manual                 7\n",
       "knnp__agnews          data_demonstrations    7\n",
       "knnp__cb              data_demonstrations    7\n",
       "knnp__cr              data_demonstrations    7\n",
       "knnp__dbpedia         data_demonstrations    7\n",
       "knnp__mpqa            data_demonstrations    7\n",
       "knnp__mr              data_demonstrations    7\n",
       "knnp__rte             data_demonstrations    7\n",
       "knnp__sst2            data_demonstrations    7\n",
       "knnp__subj            data_demonstrations    7\n",
       "knnp__trec            data_demonstrations    7\n",
       "rotten_tomatoes       manual                 7\n",
       "sst2                  manual                 7\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):\n",
    "    display(r.groupby(['dataset_name', 'prompt_source']).size())\n",
    "    # display(r.groupby(['dataset_name', 'prompt_source'])\n",
    "    # ['checkpoint'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/105 [00:00<01:19,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.354\n",
      "emotion gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/105 [00:01<01:45,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.376\n",
      "emotion gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/105 [00:03<01:50,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.394\n",
      "emotion meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/105 [00:04<01:54,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.354\n",
      "emotion gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 5/105 [00:05<01:52,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.393\n",
      "emotion EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/105 [00:06<01:50,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.333\n",
      "emotion gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/105 [00:07<01:02,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.375\n",
      "financial_phrasebank gpt2-medium\n",
      "acc improvement 0.197\n",
      "financial_phrasebank EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 10/105 [00:07<00:37,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.232\n",
      "financial_phrasebank gpt2-large\n",
      "acc improvement 0.225\n",
      "financial_phrasebank llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 12/105 [00:07<00:26,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.225\n",
      "financial_phrasebank gpt2\n",
      "acc improvement 0.101\n",
      "financial_phrasebank meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 14/105 [00:08<00:20,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.239\n",
      "financial_phrasebank gpt2-xl\n",
      "acc improvement 0.22\n",
      "imdb llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 15/105 [00:10<01:27,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.382\n",
      "imdb gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 16/105 [00:13<02:01,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.366\n",
      "imdb EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 17/105 [00:15<02:32,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.335\n",
      "imdb gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 18/105 [00:17<02:26,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.399\n",
      "imdb meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 19/105 [00:18<02:19,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.359\n",
      "imdb gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 20/105 [00:20<02:16,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.349\n",
      "imdb gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 21/105 [00:21<02:13,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.407\n",
      "knnp__agnews gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 22/105 [00:22<01:41,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.367\n",
      "knnp__agnews meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 23/105 [00:22<01:19,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.566\n",
      "knnp__agnews llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 24/105 [00:22<01:02,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.453\n",
      "knnp__agnews gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 25/105 [00:23<00:52,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.504\n",
      "knnp__agnews gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 26/105 [00:23<00:46,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.43\n",
      "knnp__agnews gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 27/105 [00:23<00:39,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.477\n",
      "knnp__agnews EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 28/105 [00:24<00:35,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.52\n",
      "knnp__cb gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 29/105 [00:24<00:32,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.196\n",
      "knnp__cb gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 30/105 [00:25<00:30,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.196\n",
      "knnp__cb llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 31/105 [00:25<00:28,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.0\n",
      "knnp__cb gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 32/105 [00:25<00:27,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.036\n",
      "knnp__cb gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 33/105 [00:26<00:27,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.036\n",
      "knnp__cb EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 34/105 [00:26<00:26,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.268\n",
      "knnp__cb meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 36/105 [00:27<00:21,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.196\n",
      "knnp__cr EleutherAI/gpt-j-6B\n",
      "acc improvement 0.168\n",
      "knnp__cr llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 38/105 [00:27<00:16,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.301\n",
      "knnp__cr gpt2\n",
      "acc improvement 0.246\n",
      "knnp__cr gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 40/105 [00:27<00:13,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.168\n",
      "knnp__cr gpt2-xl\n",
      "acc improvement 0.281\n",
      "knnp__cr gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 42/105 [00:28<00:11,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.352\n",
      "knnp__cr meta-llama/Llama-2-7b-hf\n",
      "acc improvement 0.355\n",
      "knnp__dbpedia gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 43/105 [00:30<00:44,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.098\n",
      "knnp__dbpedia gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 44/105 [00:31<00:50,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.172\n",
      "knnp__dbpedia gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 45/105 [00:32<00:54,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.152\n",
      "knnp__dbpedia llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 46/105 [00:43<04:04,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.098\n",
      "knnp__dbpedia EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 47/105 [00:45<03:14,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.141\n",
      "knnp__dbpedia meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 48/105 [00:46<02:33,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.148\n",
      "knnp__dbpedia gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 49/105 [00:47<02:02,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.133\n",
      "knnp__mpqa gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 51/105 [00:47<01:03,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.133\n",
      "knnp__mpqa llama_7b\n",
      "acc improvement -0.004\n",
      "knnp__mpqa EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 53/105 [00:48<00:34,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.203\n",
      "knnp__mpqa gpt2\n",
      "acc improvement 0.215\n",
      "knnp__mpqa gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 55/105 [00:49<00:25,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.117\n",
      "knnp__mpqa gpt2-xl\n",
      "acc improvement 0.203\n",
      "knnp__mpqa meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 56/105 [00:49<00:21,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.312\n",
      "knnp__mr gpt2-xl\n",
      "acc improvement 0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 58/105 [00:49<00:14,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knnp__mr EleutherAI/gpt-j-6B\n",
      "acc improvement 0.375\n",
      "knnp__mr gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 59/105 [00:49<00:12,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.18\n",
      "knnp__mr llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 61/105 [00:50<00:12,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.277\n",
      "knnp__mr gpt2-large\n",
      "acc improvement 0.336\n",
      "knnp__mr gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 63/105 [00:51<00:10,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.055\n",
      "knnp__mr meta-llama/Llama-2-7b-hf\n",
      "acc improvement 0.422\n",
      "knnp__rte llama_7b\n",
      "acc improvement -0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 64/105 [00:51<00:10,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knnp__rte EleutherAI/gpt-j-6B\n",
      "acc improvement 0.086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 65/105 [00:51<00:09,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knnp__rte gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 66/105 [00:51<00:11,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.023\n",
      "knnp__rte gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 67/105 [00:52<00:09,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.012\n",
      "knnp__rte meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 68/105 [00:52<00:14,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.27\n",
      "knnp__rte gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 69/105 [00:52<00:11,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement -0.027\n",
      "knnp__rte gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 71/105 [00:53<00:08,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.047\n",
      "knnp__sst2 gpt2-large\n",
      "acc improvement 0.312\n",
      "knnp__sst2 EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 73/105 [00:53<00:06,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.414\n",
      "knnp__sst2 gpt2-xl\n",
      "acc improvement 0.363\n",
      "knnp__sst2 gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 75/105 [00:54<00:06,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.328\n",
      "knnp__sst2 llama_7b\n",
      "acc improvement 0.281\n",
      "knnp__sst2 gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 77/105 [00:54<00:05,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.156\n",
      "knnp__sst2 meta-llama/Llama-2-7b-hf\n",
      "acc improvement 0.426\n",
      "knnp__subj meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 79/105 [00:54<00:04,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.387\n",
      "knnp__subj gpt2-xl\n",
      "acc improvement 0.336\n",
      "knnp__subj llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 81/105 [00:55<00:05,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.039\n",
      "knnp__subj gpt2\n",
      "acc improvement 0.039\n",
      "knnp__subj EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 83/105 [00:55<00:04,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.434\n",
      "knnp__subj gpt2-large\n",
      "acc improvement 0.379\n",
      "knnp__subj gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 85/105 [00:56<00:03,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.324\n",
      "knnp__trec EleutherAI/gpt-j-6B\n",
      "acc improvement 0.34\n",
      "knnp__trec llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 87/105 [00:56<00:04,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.312\n",
      "knnp__trec gpt2-medium\n",
      "acc improvement 0.211\n",
      "knnp__trec gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 88/105 [00:56<00:04,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.312\n",
      "knnp__trec gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 89/105 [00:57<00:03,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.223\n",
      "knnp__trec meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 91/105 [00:57<00:03,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.434\n",
      "knnp__trec gpt2-xl\n",
      "acc improvement 0.297\n",
      "rotten_tomatoes gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 92/105 [00:59<00:09,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.336\n",
      "rotten_tomatoes gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 93/105 [00:59<00:07,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.337\n",
      "rotten_tomatoes gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 94/105 [01:00<00:06,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.265\n",
      "rotten_tomatoes gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 95/105 [01:00<00:05,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.29\n",
      "rotten_tomatoes EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 96/105 [01:01<00:04,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.287\n",
      "rotten_tomatoes llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 97/105 [01:01<00:03,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.28\n",
      "rotten_tomatoes meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 98/105 [01:03<00:06,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.356\n",
      "sst2 meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 99/105 [01:05<00:06,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.352\n",
      "sst2 gpt2-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 100/105 [01:06<00:06,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.384\n",
      "sst2 llama_7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 101/105 [01:11<00:09,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.334\n",
      "sst2 gpt2-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 102/105 [01:13<00:06,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.385\n",
      "sst2 EleutherAI/gpt-j-6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 103/105 [01:17<00:05,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.303\n",
      "sst2 gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 104/105 [01:19<00:02,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.267\n",
      "sst2 gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [01:21<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc improvement 0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PROCESSED_DIR = os.path.expanduser('~/cost-optimal-tree/data_processed/')\n",
    "r = r.sort_values(by=['dataset_name']).reset_index().drop(columns=['index'])\n",
    "for k in ['n_train', 'n_test', 'n_prompts', 'n_outputs']:\n",
    "    r[k] = np.nan\n",
    "for i in tqdm(range(r.shape[0])):\n",
    "    args = r.iloc[i]\n",
    "    print(args.dataset_name, args.checkpoint)\n",
    "    run = joblib.load(join(args.save_dir_unique, 'cached_dset.pkl'))\n",
    "\n",
    "    out_dir = join(DATA_PROCESSED_DIR, args.dataset_name)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    X_train = run['X_train']\n",
    "    X_test = run['X_test']\n",
    "    y_train = run['y_train']\n",
    "    y_test = run['y_test']\n",
    "    feature_names = run['feature_names']\n",
    "\n",
    "    # run data checks\n",
    "    # check that X only contains ones and zeros\n",
    "    if issparse(X_train):\n",
    "        X_train = X_train.toarray()\n",
    "        X_test = X_test.toarray()\n",
    "    assert np.all(np.isin(X_train, [0, 1]))\n",
    "    assert np.all(np.isin(X_test, [0, 1]))\n",
    "\n",
    "    # remove any cols that are all the same value\n",
    "    idxs_constant = np.where(np.all(X_train == X_train[0, :], axis=0))[0]\n",
    "    # print(f'removing {idxs_constant.size} constant cols')\n",
    "    # print('unique', np.unique(X_train))\n",
    "    X_train = np.delete(X_train, idxs_constant, axis=1)\n",
    "    X_test = np.delete(X_test, idxs_constant, axis=1)\n",
    "    feature_names = np.delete(feature_names, idxs_constant)\n",
    "\n",
    "    # fit simple sklearn classifier\n",
    "    clf = DecisionTreeClassifier(random_state=42, max_depth=3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    acc_baseline = np.unique(y_test, return_counts=True)[1][0] / y_test.size\n",
    "    acc_improvement = acc - acc_baseline\n",
    "    print('acc improvement', acc_improvement.round(3))\n",
    "    # assert acc > acc_baseline\n",
    "\n",
    "    # export data\n",
    "    X_train = X_train.astype(bool)\n",
    "    X_test = X_test.astype(bool)\n",
    "\n",
    "    joblib.dump(\n",
    "        {\n",
    "            'X_train': X_train,\n",
    "            'X_test': X_test,\n",
    "            # 'y_train': y_train,\n",
    "            # 'y_test': y_test,\n",
    "            'feature_names': feature_names,\n",
    "            'verbalizer': args['verbalizer'],\n",
    "            'acc_improvement': acc_improvement,\n",
    "            'acc': acc,\n",
    "        },\n",
    "        join(out_dir, imodelsx.viz.CHECKPOINTS_RENAME_DICT.get(\n",
    "            args.checkpoint) + '_features.pkl')\n",
    "    )\n",
    "    joblib.dump({\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "    }, join(out_dir, 'labels.pkl'))\n",
    "\n",
    "    r.loc[i, 'n_train'] = X_train.shape[0]\n",
    "    r.loc[i, 'n_test'] = X_test.shape[0]\n",
    "    r.loc[i, 'n_prompts'] = X_train.shape[1]\n",
    "    r.loc[i, 'n_outputs'] = np.unique(y_train).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n_prompts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_name</th>\n",
       "      <th>prompt_source</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_outputs</th>\n",
       "      <th>checkpoint</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">emotion</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">manual</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">10028.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">1254.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">financial_phrasebank</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">manual</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">871.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">436.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">imdb</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">manual</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">25000.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">25000.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">knnp__agnews</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">4.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">knnp__cb</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">56.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">3.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">knnp__cr</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">knnp__dbpedia</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">14.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>439.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">knnp__mpqa</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">knnp__mr</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">knnp__rte</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">knnp__sst2</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">knnp__subj</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">knnp__trec</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">data_demonstrations</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">100.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">256.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">6.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">rotten_tomatoes</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">manual</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">8530.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">1066.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">sst2</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">manual</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">67349.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">872.0</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">2.0</th>\n",
       "      <th>EleutherAI/gpt-j-6B</th>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-large</th>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-medium</th>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-hf</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             n_prompts\n",
       "dataset_name         prompt_source       n_train n_test  n_outputs checkpoint                         \n",
       "emotion              manual              10028.0 1254.0  2.0       EleutherAI/gpt-j-6B            32.0\n",
       "                                                                   gpt2                           32.0\n",
       "                                                                   gpt2-large                     32.0\n",
       "                                                                   gpt2-medium                    32.0\n",
       "                                                                   gpt2-xl                        32.0\n",
       "                                                                   llama_7b                       32.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf       32.0\n",
       "financial_phrasebank manual              871.0   436.0   2.0       EleutherAI/gpt-j-6B            40.0\n",
       "                                                                   gpt2                           35.0\n",
       "                                                                   gpt2-large                     38.0\n",
       "                                                                   gpt2-medium                    40.0\n",
       "                                                                   gpt2-xl                        40.0\n",
       "                                                                   llama_7b                       40.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf       40.0\n",
       "imdb                 manual              25000.0 25000.0 2.0       EleutherAI/gpt-j-6B            94.0\n",
       "                                                                   gpt2                           94.0\n",
       "                                                                   gpt2-large                     94.0\n",
       "                                                                   gpt2-medium                    90.0\n",
       "                                                                   gpt2-xl                        94.0\n",
       "                                                                   llama_7b                       94.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf       94.0\n",
       "knnp__agnews         data_demonstrations 100.0   256.0   4.0       EleutherAI/gpt-j-6B           160.0\n",
       "                                                                   gpt2                          150.0\n",
       "                                                                   gpt2-large                    151.0\n",
       "                                                                   gpt2-medium                   143.0\n",
       "                                                                   gpt2-xl                       154.0\n",
       "                                                                   llama_7b                      160.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf      160.0\n",
       "knnp__cb             data_demonstrations 100.0   56.0    3.0       EleutherAI/gpt-j-6B           120.0\n",
       "                                                                   gpt2                          109.0\n",
       "                                                                   gpt2-large                    119.0\n",
       "                                                                   gpt2-medium                   118.0\n",
       "                                                                   gpt2-xl                       117.0\n",
       "                                                                   llama_7b                      120.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf      116.0\n",
       "knnp__cr             data_demonstrations 100.0   256.0   2.0       EleutherAI/gpt-j-6B            40.0\n",
       "                                                                   gpt2                           38.0\n",
       "                                                                   gpt2-large                     40.0\n",
       "                                                                   gpt2-medium                    40.0\n",
       "                                                                   gpt2-xl                        40.0\n",
       "                                                                   llama_7b                       40.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf       40.0\n",
       "knnp__dbpedia        data_demonstrations 100.0   256.0   14.0      EleutherAI/gpt-j-6B           558.0\n",
       "                                                                   gpt2                          439.0\n",
       "                                                                   gpt2-large                    402.0\n",
       "                                                                   gpt2-medium                   458.0\n",
       "                                                                   gpt2-xl                       519.0\n",
       "                                                                   llama_7b                      560.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf      559.0\n",
       "knnp__mpqa           data_demonstrations 100.0   256.0   2.0       EleutherAI/gpt-j-6B            40.0\n",
       "                                                                   gpt2                           40.0\n",
       "                                                                   gpt2-large                     40.0\n",
       "                                                                   gpt2-medium                    40.0\n",
       "                                                                   gpt2-xl                        40.0\n",
       "                                                                   llama_7b                       40.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf       40.0\n",
       "knnp__mr             data_demonstrations 100.0   256.0   2.0       EleutherAI/gpt-j-6B            40.0\n",
       "                                                                   gpt2                           39.0\n",
       "                                                                   gpt2-large                     40.0\n",
       "                                                                   gpt2-medium                    39.0\n",
       "                                                                   gpt2-xl                        40.0\n",
       "                                                                   llama_7b                       40.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf       40.0\n",
       "knnp__rte            data_demonstrations 100.0   256.0   2.0       EleutherAI/gpt-j-6B            40.0\n",
       "                                                                   gpt2                           36.0\n",
       "                                                                   gpt2-large                     40.0\n",
       "                                                                   gpt2-medium                    40.0\n",
       "                                                                   gpt2-xl                        40.0\n",
       "                                                                   llama_7b                       40.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf       40.0\n",
       "knnp__sst2           data_demonstrations 100.0   256.0   2.0       EleutherAI/gpt-j-6B            40.0\n",
       "                                                                   gpt2                           40.0\n",
       "                                                                   gpt2-large                     40.0\n",
       "                                                                   gpt2-medium                    40.0\n",
       "                                                                   gpt2-xl                        40.0\n",
       "                                                                   llama_7b                       40.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf       40.0\n",
       "knnp__subj           data_demonstrations 100.0   256.0   2.0       EleutherAI/gpt-j-6B            40.0\n",
       "                                                                   gpt2                           24.0\n",
       "                                                                   gpt2-large                     40.0\n",
       "                                                                   gpt2-medium                    39.0\n",
       "                                                                   gpt2-xl                        40.0\n",
       "                                                                   llama_7b                       40.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf       37.0\n",
       "knnp__trec           data_demonstrations 100.0   256.0   6.0       EleutherAI/gpt-j-6B           240.0\n",
       "                                                                   gpt2                          235.0\n",
       "                                                                   gpt2-large                    240.0\n",
       "                                                                   gpt2-medium                   240.0\n",
       "                                                                   gpt2-xl                       240.0\n",
       "                                                                   llama_7b                      178.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf      240.0\n",
       "rotten_tomatoes      manual              8530.0  1066.0  2.0       EleutherAI/gpt-j-6B            87.0\n",
       "                                                                   gpt2                           85.0\n",
       "                                                                   gpt2-large                     87.0\n",
       "                                                                   gpt2-medium                    81.0\n",
       "                                                                   gpt2-xl                        86.0\n",
       "                                                                   llama_7b                       94.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf       94.0\n",
       "sst2                 manual              67349.0 872.0   2.0       EleutherAI/gpt-j-6B            89.0\n",
       "                                                                   gpt2                           87.0\n",
       "                                                                   gpt2-large                     88.0\n",
       "                                                                   gpt2-medium                    82.0\n",
       "                                                                   gpt2-xl                        91.0\n",
       "                                                                   llama_7b                       94.0\n",
       "                                                                   meta-llama/Llama-2-7b-hf       94.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):\n",
    "    metadata = r.groupby(['dataset_name', 'prompt_source', 'n_train',\n",
    "                          'n_test', 'n_outputs', 'checkpoint'])[['n_prompts']].sum()\n",
    "    display(metadata)\n",
    "metadata.to_pickle(join(DATA_PROCESSED_DIR, 'metadata.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
