{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:00<00:00, 2417.59it/s]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import imodelsx.process_results\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import viz\n",
    "import sys\n",
    "sys.path.append('../experiments/')\n",
    "results_dir = '/home/chansingh/mntv1/tree-prompt/aug22_vary_train_test'\n",
    "\n",
    "r = imodelsx.process_results.get_results_df(results_dir)\n",
    "experiment_filename = '../experiments/01_fit.py'\n",
    "r = imodelsx.process_results.fill_missing_args_with_default(r, experiment_filename)\n",
    "metric = 'roc_auc_test'\n",
    "r['suffix'] = ''\n",
    "r.loc[r['num_prompts'] == 1, 'model_name'] = 'single prompt'\n",
    "ks = [\"dataset_name\", \"checkpoint\", \"checkpoint_evaluation\", \"model_name\"]\n",
    "r = r[ks + [metric]].sort_values(by=ks)\n",
    "r['dataset_name'] = r['dataset_name'].map(imodelsx.viz.DSETS_RENAME_DICT.get)\n",
    "r['checkpoint'] = r['checkpoint'].map(imodelsx.viz.CHECKPOINTS_RENAME_DICT.get)\n",
    "r['checkpoint_evaluation'] = r['checkpoint_evaluation'].map(imodelsx.viz.CHECKPOINTS_RENAME_DICT.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>checkpoint_evaluation</th>\n",
       "      <th>model_name</th>\n",
       "      <th>roc_auc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.795684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.741200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.613864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.611814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.613771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.553500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.612666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.618291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.617217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.599029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.613730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.566476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.799443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.781564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.629007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.646903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.604735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.567528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.656950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.667225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.564529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.609232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.614549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.590666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.818748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.772263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.584011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.906838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.859142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.678607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.696021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.605103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.590945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.734942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.550976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.586772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.739794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.697168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.854653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.822856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.639064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.757940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.745245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.512641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.757073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.592814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.622733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.737170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.608692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.573962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.915219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.855828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.673743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Financial phrasebank</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IMDB</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.967306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>IMDB</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.948624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>IMDB</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>IMDB</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.880549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>IMDB</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.859620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>IMDB</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.844160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>IMDB</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.833788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>IMDB</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.847132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>IMDB</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>IMDB</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.930003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>IMDB</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.919049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>IMDB</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.844160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.918534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.882225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.756098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.829993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.819909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.774859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.895211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.881238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.818011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.790418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.743719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.742026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.858983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.838572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.752345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.834724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.811809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.806754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.819940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.765473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.756098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.841974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.804447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.774859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.927088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.910848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.818011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Rotten tomatoes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.935982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.903148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.765324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.886609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.826061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.713543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.939615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.912288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.867254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.887477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.832597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.765324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.897078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.889679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.713543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.936434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.935040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.867254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.822006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.837625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-J (6B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.765324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.879960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.866136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (117M)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.713543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_gbdt</td>\n",
       "      <td>0.948793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>manual_tree</td>\n",
       "      <td>0.944833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SST2</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>single prompt</td>\n",
       "      <td>0.867254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dataset_name    checkpoint checkpoint_evaluation     model_name  \\\n",
       "122               Emotion    GPT-J (6B)            GPT-J (6B)    manual_gbdt   \n",
       "112               Emotion    GPT-J (6B)            GPT-J (6B)    manual_tree   \n",
       "121               Emotion    GPT-J (6B)            GPT-J (6B)  single prompt   \n",
       "76                Emotion    GPT-J (6B)          GPT-2 (117M)    manual_gbdt   \n",
       "33                Emotion    GPT-J (6B)          GPT-2 (117M)    manual_tree   \n",
       "60                Emotion    GPT-J (6B)          GPT-2 (117M)  single prompt   \n",
       "5                 Emotion    GPT-J (6B)          GPT-2 (1.5B)    manual_gbdt   \n",
       "17                Emotion    GPT-J (6B)          GPT-2 (1.5B)    manual_tree   \n",
       "68                Emotion    GPT-J (6B)          GPT-2 (1.5B)  single prompt   \n",
       "115               Emotion  GPT-2 (117M)            GPT-J (6B)    manual_gbdt   \n",
       "38                Emotion  GPT-2 (117M)            GPT-J (6B)    manual_tree   \n",
       "119               Emotion  GPT-2 (117M)            GPT-J (6B)  single prompt   \n",
       "107               Emotion  GPT-2 (117M)          GPT-2 (117M)    manual_gbdt   \n",
       "55                Emotion  GPT-2 (117M)          GPT-2 (117M)    manual_tree   \n",
       "65                Emotion  GPT-2 (117M)          GPT-2 (117M)  single prompt   \n",
       "51                Emotion  GPT-2 (117M)          GPT-2 (1.5B)    manual_gbdt   \n",
       "40                Emotion  GPT-2 (117M)          GPT-2 (1.5B)    manual_tree   \n",
       "48                Emotion  GPT-2 (117M)          GPT-2 (1.5B)  single prompt   \n",
       "116               Emotion  GPT-2 (1.5B)            GPT-J (6B)    manual_gbdt   \n",
       "80                Emotion  GPT-2 (1.5B)            GPT-J (6B)    manual_tree   \n",
       "46                Emotion  GPT-2 (1.5B)            GPT-J (6B)  single prompt   \n",
       "91                Emotion  GPT-2 (1.5B)          GPT-2 (117M)    manual_gbdt   \n",
       "34                Emotion  GPT-2 (1.5B)          GPT-2 (117M)    manual_tree   \n",
       "35                Emotion  GPT-2 (1.5B)          GPT-2 (117M)  single prompt   \n",
       "32                Emotion  GPT-2 (1.5B)          GPT-2 (1.5B)    manual_gbdt   \n",
       "58                Emotion  GPT-2 (1.5B)          GPT-2 (1.5B)    manual_tree   \n",
       "67                Emotion  GPT-2 (1.5B)          GPT-2 (1.5B)  single prompt   \n",
       "96                Emotion          None                  None  single prompt   \n",
       "85   Financial phrasebank    GPT-J (6B)            GPT-J (6B)    manual_gbdt   \n",
       "37   Financial phrasebank    GPT-J (6B)            GPT-J (6B)    manual_tree   \n",
       "97   Financial phrasebank    GPT-J (6B)            GPT-J (6B)  single prompt   \n",
       "57   Financial phrasebank    GPT-J (6B)          GPT-2 (117M)    manual_gbdt   \n",
       "105  Financial phrasebank    GPT-J (6B)          GPT-2 (117M)    manual_tree   \n",
       "74   Financial phrasebank    GPT-J (6B)          GPT-2 (117M)  single prompt   \n",
       "53   Financial phrasebank    GPT-J (6B)          GPT-2 (1.5B)    manual_gbdt   \n",
       "94   Financial phrasebank    GPT-J (6B)          GPT-2 (1.5B)    manual_tree   \n",
       "30   Financial phrasebank    GPT-J (6B)          GPT-2 (1.5B)  single prompt   \n",
       "26   Financial phrasebank  GPT-2 (117M)            GPT-J (6B)    manual_gbdt   \n",
       "9    Financial phrasebank  GPT-2 (117M)            GPT-J (6B)    manual_tree   \n",
       "61   Financial phrasebank  GPT-2 (117M)            GPT-J (6B)  single prompt   \n",
       "111  Financial phrasebank  GPT-2 (117M)          GPT-2 (117M)    manual_gbdt   \n",
       "2    Financial phrasebank  GPT-2 (117M)          GPT-2 (117M)    manual_tree   \n",
       "102  Financial phrasebank  GPT-2 (117M)          GPT-2 (117M)  single prompt   \n",
       "39   Financial phrasebank  GPT-2 (117M)          GPT-2 (1.5B)    manual_gbdt   \n",
       "71   Financial phrasebank  GPT-2 (117M)          GPT-2 (1.5B)    manual_tree   \n",
       "14   Financial phrasebank  GPT-2 (117M)          GPT-2 (1.5B)  single prompt   \n",
       "7    Financial phrasebank  GPT-2 (1.5B)            GPT-J (6B)    manual_gbdt   \n",
       "86   Financial phrasebank  GPT-2 (1.5B)            GPT-J (6B)    manual_tree   \n",
       "25   Financial phrasebank  GPT-2 (1.5B)            GPT-J (6B)  single prompt   \n",
       "108  Financial phrasebank  GPT-2 (1.5B)          GPT-2 (117M)    manual_gbdt   \n",
       "75   Financial phrasebank  GPT-2 (1.5B)          GPT-2 (117M)    manual_tree   \n",
       "23   Financial phrasebank  GPT-2 (1.5B)          GPT-2 (117M)  single prompt   \n",
       "18   Financial phrasebank  GPT-2 (1.5B)          GPT-2 (1.5B)    manual_gbdt   \n",
       "15   Financial phrasebank  GPT-2 (1.5B)          GPT-2 (1.5B)    manual_tree   \n",
       "117  Financial phrasebank  GPT-2 (1.5B)          GPT-2 (1.5B)  single prompt   \n",
       "72   Financial phrasebank          None                  None  single prompt   \n",
       "47                   IMDB    GPT-J (6B)            GPT-J (6B)    manual_gbdt   \n",
       "64                   IMDB    GPT-J (6B)            GPT-J (6B)    manual_tree   \n",
       "66                   IMDB    GPT-J (6B)            GPT-J (6B)  single prompt   \n",
       "88                   IMDB    GPT-J (6B)          GPT-2 (117M)    manual_gbdt   \n",
       "113                  IMDB    GPT-J (6B)          GPT-2 (117M)    manual_tree   \n",
       "89                   IMDB    GPT-J (6B)          GPT-2 (117M)  single prompt   \n",
       "62                   IMDB  GPT-2 (117M)            GPT-J (6B)    manual_gbdt   \n",
       "59                   IMDB  GPT-2 (117M)            GPT-J (6B)    manual_tree   \n",
       "24                   IMDB  GPT-2 (117M)            GPT-J (6B)  single prompt   \n",
       "114                  IMDB  GPT-2 (117M)          GPT-2 (117M)    manual_gbdt   \n",
       "110                  IMDB  GPT-2 (117M)          GPT-2 (117M)    manual_tree   \n",
       "118                  IMDB  GPT-2 (117M)          GPT-2 (117M)  single prompt   \n",
       "81        Rotten tomatoes    GPT-J (6B)            GPT-J (6B)    manual_gbdt   \n",
       "101       Rotten tomatoes    GPT-J (6B)            GPT-J (6B)    manual_tree   \n",
       "109       Rotten tomatoes    GPT-J (6B)            GPT-J (6B)  single prompt   \n",
       "19        Rotten tomatoes    GPT-J (6B)          GPT-2 (117M)    manual_gbdt   \n",
       "82        Rotten tomatoes    GPT-J (6B)          GPT-2 (117M)    manual_tree   \n",
       "92        Rotten tomatoes    GPT-J (6B)          GPT-2 (117M)  single prompt   \n",
       "22        Rotten tomatoes    GPT-J (6B)          GPT-2 (1.5B)    manual_gbdt   \n",
       "41        Rotten tomatoes    GPT-J (6B)          GPT-2 (1.5B)    manual_tree   \n",
       "87        Rotten tomatoes    GPT-J (6B)          GPT-2 (1.5B)  single prompt   \n",
       "13        Rotten tomatoes  GPT-2 (117M)            GPT-J (6B)    manual_gbdt   \n",
       "73        Rotten tomatoes  GPT-2 (117M)            GPT-J (6B)    manual_tree   \n",
       "95        Rotten tomatoes  GPT-2 (117M)            GPT-J (6B)  single prompt   \n",
       "69        Rotten tomatoes  GPT-2 (117M)          GPT-2 (117M)    manual_gbdt   \n",
       "0         Rotten tomatoes  GPT-2 (117M)          GPT-2 (117M)    manual_tree   \n",
       "70        Rotten tomatoes  GPT-2 (117M)          GPT-2 (117M)  single prompt   \n",
       "20        Rotten tomatoes  GPT-2 (117M)          GPT-2 (1.5B)    manual_gbdt   \n",
       "44        Rotten tomatoes  GPT-2 (117M)          GPT-2 (1.5B)    manual_tree   \n",
       "21        Rotten tomatoes  GPT-2 (117M)          GPT-2 (1.5B)  single prompt   \n",
       "43        Rotten tomatoes  GPT-2 (1.5B)            GPT-J (6B)    manual_gbdt   \n",
       "77        Rotten tomatoes  GPT-2 (1.5B)            GPT-J (6B)    manual_tree   \n",
       "3         Rotten tomatoes  GPT-2 (1.5B)            GPT-J (6B)  single prompt   \n",
       "1         Rotten tomatoes  GPT-2 (1.5B)          GPT-2 (117M)    manual_gbdt   \n",
       "45        Rotten tomatoes  GPT-2 (1.5B)          GPT-2 (117M)    manual_tree   \n",
       "28        Rotten tomatoes  GPT-2 (1.5B)          GPT-2 (117M)  single prompt   \n",
       "36        Rotten tomatoes  GPT-2 (1.5B)          GPT-2 (1.5B)    manual_gbdt   \n",
       "27        Rotten tomatoes  GPT-2 (1.5B)          GPT-2 (1.5B)    manual_tree   \n",
       "6         Rotten tomatoes  GPT-2 (1.5B)          GPT-2 (1.5B)  single prompt   \n",
       "103       Rotten tomatoes          None                  None  single prompt   \n",
       "84                   SST2    GPT-J (6B)            GPT-J (6B)    manual_gbdt   \n",
       "4                    SST2    GPT-J (6B)            GPT-J (6B)    manual_tree   \n",
       "10                   SST2    GPT-J (6B)            GPT-J (6B)  single prompt   \n",
       "106                  SST2    GPT-J (6B)          GPT-2 (117M)    manual_gbdt   \n",
       "120                  SST2    GPT-J (6B)          GPT-2 (117M)    manual_tree   \n",
       "54                   SST2    GPT-J (6B)          GPT-2 (117M)  single prompt   \n",
       "78                   SST2    GPT-J (6B)          GPT-2 (1.5B)    manual_gbdt   \n",
       "8                    SST2    GPT-J (6B)          GPT-2 (1.5B)    manual_tree   \n",
       "11                   SST2    GPT-J (6B)          GPT-2 (1.5B)  single prompt   \n",
       "31                   SST2  GPT-2 (117M)            GPT-J (6B)    manual_gbdt   \n",
       "99                   SST2  GPT-2 (117M)            GPT-J (6B)    manual_tree   \n",
       "16                   SST2  GPT-2 (117M)            GPT-J (6B)  single prompt   \n",
       "90                   SST2  GPT-2 (117M)          GPT-2 (117M)    manual_gbdt   \n",
       "63                   SST2  GPT-2 (117M)          GPT-2 (117M)    manual_tree   \n",
       "98                   SST2  GPT-2 (117M)          GPT-2 (117M)  single prompt   \n",
       "12                   SST2  GPT-2 (117M)          GPT-2 (1.5B)    manual_gbdt   \n",
       "50                   SST2  GPT-2 (117M)          GPT-2 (1.5B)    manual_tree   \n",
       "56                   SST2  GPT-2 (117M)          GPT-2 (1.5B)  single prompt   \n",
       "83                   SST2  GPT-2 (1.5B)            GPT-J (6B)    manual_gbdt   \n",
       "104                  SST2  GPT-2 (1.5B)            GPT-J (6B)    manual_tree   \n",
       "52                   SST2  GPT-2 (1.5B)            GPT-J (6B)  single prompt   \n",
       "42                   SST2  GPT-2 (1.5B)          GPT-2 (117M)    manual_gbdt   \n",
       "79                   SST2  GPT-2 (1.5B)          GPT-2 (117M)    manual_tree   \n",
       "49                   SST2  GPT-2 (1.5B)          GPT-2 (117M)  single prompt   \n",
       "93                   SST2  GPT-2 (1.5B)          GPT-2 (1.5B)    manual_gbdt   \n",
       "100                  SST2  GPT-2 (1.5B)          GPT-2 (1.5B)    manual_tree   \n",
       "29                   SST2  GPT-2 (1.5B)          GPT-2 (1.5B)  single prompt   \n",
       "\n",
       "     roc_auc_test  \n",
       "122      0.795684  \n",
       "112      0.741200  \n",
       "121      0.613864  \n",
       "76       0.611814  \n",
       "33       0.613771  \n",
       "60       0.553500  \n",
       "5        0.612666  \n",
       "17       0.618291  \n",
       "68       0.617217  \n",
       "115      0.599029  \n",
       "38       0.613730  \n",
       "119      0.566476  \n",
       "107      0.799443  \n",
       "55       0.781564  \n",
       "65       0.629007  \n",
       "51       0.646903  \n",
       "40       0.604735  \n",
       "48       0.567528  \n",
       "116      0.656950  \n",
       "80       0.667225  \n",
       "46       0.564529  \n",
       "91       0.609232  \n",
       "34       0.614549  \n",
       "35       0.590666  \n",
       "32       0.818748  \n",
       "58       0.772263  \n",
       "67       0.584011  \n",
       "96       0.500000  \n",
       "85       0.906838  \n",
       "37       0.859142  \n",
       "97       0.678607  \n",
       "57       0.696021  \n",
       "105      0.605103  \n",
       "74       0.590945  \n",
       "53       0.734942  \n",
       "94       0.550976  \n",
       "30       0.586772  \n",
       "26       0.739794  \n",
       "9        0.697168  \n",
       "61       0.500000  \n",
       "111      0.854653  \n",
       "2        0.822856  \n",
       "102      0.639064  \n",
       "39       0.757940  \n",
       "71       0.745245  \n",
       "14       0.512641  \n",
       "7        0.757073  \n",
       "86       0.592814  \n",
       "25       0.622733  \n",
       "108      0.737170  \n",
       "75       0.608692  \n",
       "23       0.573962  \n",
       "18       0.915219  \n",
       "15       0.855828  \n",
       "117      0.673743  \n",
       "72       0.500000  \n",
       "47       0.967306  \n",
       "64       0.948624  \n",
       "66       0.817000  \n",
       "88       0.880549  \n",
       "113      0.859620  \n",
       "89       0.844160  \n",
       "62       0.833788  \n",
       "59       0.847132  \n",
       "24       0.817000  \n",
       "114      0.930003  \n",
       "110      0.919049  \n",
       "118      0.844160  \n",
       "81       0.918534  \n",
       "101      0.882225  \n",
       "109      0.756098  \n",
       "19       0.829993  \n",
       "82       0.819909  \n",
       "92       0.774859  \n",
       "22       0.895211  \n",
       "41       0.881238  \n",
       "87       0.818011  \n",
       "13       0.790418  \n",
       "73       0.743719  \n",
       "95       0.742026  \n",
       "69       0.858983  \n",
       "0        0.838572  \n",
       "70       0.752345  \n",
       "20       0.834724  \n",
       "44       0.811809  \n",
       "21       0.806754  \n",
       "43       0.819940  \n",
       "77       0.765473  \n",
       "3        0.756098  \n",
       "1        0.841974  \n",
       "45       0.804447  \n",
       "28       0.774859  \n",
       "36       0.927088  \n",
       "27       0.910848  \n",
       "6        0.818011  \n",
       "103      0.500000  \n",
       "84       0.935982  \n",
       "4        0.903148  \n",
       "10       0.765324  \n",
       "106      0.886609  \n",
       "120      0.826061  \n",
       "54       0.713543  \n",
       "78       0.939615  \n",
       "8        0.912288  \n",
       "11       0.867254  \n",
       "31       0.887477  \n",
       "99       0.832597  \n",
       "16       0.765324  \n",
       "90       0.897078  \n",
       "63       0.889679  \n",
       "98       0.713543  \n",
       "12       0.936434  \n",
       "50       0.935040  \n",
       "56       0.867254  \n",
       "83       0.822006  \n",
       "104      0.837625  \n",
       "52       0.765324  \n",
       "42       0.879960  \n",
       "79       0.866136  \n",
       "49       0.713543  \n",
       "93       0.948793  \n",
       "100      0.944833  \n",
       "29       0.867254  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display all rows\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    display(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = r[\n",
    "    ~(\n",
    "        r[\"checkpoint\"].str.contains(\"llama\", case=False)\n",
    "        | r[\"checkpoint_evaluation\"].str.contains(\"llama\", case=False)\n",
    "        | (r[\"dataset_name\"] == \"IMDB\")\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_without_dset = [k for k in ks if not k == 'dataset_name']\n",
    "groups = r.groupby(group_without_dset)[metric]\n",
    "means = groups.mean().reset_index()\n",
    "# means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did all models run for all datasets? If not then we need to finish the experiments with lower batch sizes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "checkpoint    checkpoint_evaluation  model_name   \n",
       "GPT-2 (1.5B)  GPT-2 (1.5B)           manual_gbdt      4\n",
       "                                     manual_tree      4\n",
       "                                     single prompt    4\n",
       "              GPT-2 (117M)           manual_gbdt      4\n",
       "                                     manual_tree      4\n",
       "                                     single prompt    4\n",
       "              GPT-J (6B)             manual_gbdt      4\n",
       "                                     manual_tree      4\n",
       "                                     single prompt    4\n",
       "GPT-2 (117M)  GPT-2 (1.5B)           manual_gbdt      4\n",
       "                                     manual_tree      4\n",
       "                                     single prompt    4\n",
       "              GPT-2 (117M)           manual_gbdt      4\n",
       "                                     manual_tree      4\n",
       "                                     single prompt    4\n",
       "              GPT-J (6B)             manual_gbdt      4\n",
       "                                     manual_tree      4\n",
       "                                     single prompt    4\n",
       "GPT-J (6B)    GPT-2 (1.5B)           manual_gbdt      4\n",
       "                                     manual_tree      4\n",
       "                                     single prompt    4\n",
       "              GPT-2 (117M)           manual_gbdt      4\n",
       "                                     manual_tree      4\n",
       "                                     single prompt    4\n",
       "              GPT-J (6B)             manual_gbdt      4\n",
       "                                     manual_tree      4\n",
       "                                     single prompt    4\n",
       "Name: roc_auc_test, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Did all models run for all datasets? If not then we need to finish the experiments with lower batch sizes.')\n",
    "groups.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bbe5e_row0_col0, #T_bbe5e_row3_col1, #T_bbe5e_row6_col2 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bbe5e_row0_col1 {\n",
       "  background-color: #57a0ce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bbe5e_row0_col2 {\n",
       "  background-color: #6fb0d7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bbe5e_row1_col0 {\n",
       "  background-color: #0c56a0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bbe5e_row1_col1 {\n",
       "  background-color: #abd0e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bbe5e_row1_col2 {\n",
       "  background-color: #b8d5ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bbe5e_row2_col0 {\n",
       "  background-color: #ccdff1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bbe5e_row2_col1 {\n",
       "  background-color: #f2f8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bbe5e_row2_col2 {\n",
       "  background-color: #dce9f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bbe5e_row3_col0 {\n",
       "  background-color: #6dafd7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bbe5e_row3_col2 {\n",
       "  background-color: #7fb9da;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bbe5e_row4_col0 {\n",
       "  background-color: #94c4df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bbe5e_row4_col1 {\n",
       "  background-color: #084a91;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bbe5e_row4_col2 {\n",
       "  background-color: #b0d2e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bbe5e_row5_col0, #T_bbe5e_row5_col2, #T_bbe5e_row8_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bbe5e_row5_col1 {\n",
       "  background-color: #ddeaf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bbe5e_row6_col0, #T_bbe5e_row6_col1 {\n",
       "  background-color: #6aaed6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bbe5e_row7_col0, #T_bbe5e_row8_col2 {\n",
       "  background-color: #c7dcef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bbe5e_row7_col1 {\n",
       "  background-color: #b7d4ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bbe5e_row7_col2 {\n",
       "  background-color: #125da6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bbe5e_row8_col0 {\n",
       "  background-color: #d8e7f5;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bbe5e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >checkpoint_evaluation</th>\n",
       "      <th id=\"T_bbe5e_level0_col0\" class=\"col_heading level0 col0\" >GPT-2 (1.5B)</th>\n",
       "      <th id=\"T_bbe5e_level0_col1\" class=\"col_heading level0 col1\" >GPT-2 (117M)</th>\n",
       "      <th id=\"T_bbe5e_level0_col2\" class=\"col_heading level0 col2\" >GPT-J (6B)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >checkpoint</th>\n",
       "      <th class=\"index_name level1\" >model_name</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bbe5e_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"3\">GPT-2 (1.5B)</th>\n",
       "      <th id=\"T_bbe5e_level1_row0\" class=\"row_heading level1 row0\" >manual_gbdt</th>\n",
       "      <td id=\"T_bbe5e_row0_col0\" class=\"data row0 col0\" >0.90</td>\n",
       "      <td id=\"T_bbe5e_row0_col1\" class=\"data row0 col1\" >0.77</td>\n",
       "      <td id=\"T_bbe5e_row0_col2\" class=\"data row0 col2\" >0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbe5e_level1_row1\" class=\"row_heading level1 row1\" >manual_tree</th>\n",
       "      <td id=\"T_bbe5e_row1_col0\" class=\"data row1 col0\" >0.87</td>\n",
       "      <td id=\"T_bbe5e_row1_col1\" class=\"data row1 col1\" >0.72</td>\n",
       "      <td id=\"T_bbe5e_row1_col2\" class=\"data row1 col2\" >0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbe5e_level1_row2\" class=\"row_heading level1 row2\" >single prompt</th>\n",
       "      <td id=\"T_bbe5e_row2_col0\" class=\"data row2 col0\" >0.74</td>\n",
       "      <td id=\"T_bbe5e_row2_col1\" class=\"data row2 col1\" >0.66</td>\n",
       "      <td id=\"T_bbe5e_row2_col2\" class=\"data row2 col2\" >0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbe5e_level0_row3\" class=\"row_heading level0 row3\" rowspan=\"3\">GPT-2 (117M)</th>\n",
       "      <th id=\"T_bbe5e_level1_row3\" class=\"row_heading level1 row3\" >manual_gbdt</th>\n",
       "      <td id=\"T_bbe5e_row3_col0\" class=\"data row3 col0\" >0.79</td>\n",
       "      <td id=\"T_bbe5e_row3_col1\" class=\"data row3 col1\" >0.85</td>\n",
       "      <td id=\"T_bbe5e_row3_col2\" class=\"data row3 col2\" >0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbe5e_level1_row4\" class=\"row_heading level1 row4\" >manual_tree</th>\n",
       "      <td id=\"T_bbe5e_row4_col0\" class=\"data row4 col0\" >0.77</td>\n",
       "      <td id=\"T_bbe5e_row4_col1\" class=\"data row4 col1\" >0.83</td>\n",
       "      <td id=\"T_bbe5e_row4_col2\" class=\"data row4 col2\" >0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbe5e_level1_row5\" class=\"row_heading level1 row5\" >single prompt</th>\n",
       "      <td id=\"T_bbe5e_row5_col0\" class=\"data row5 col0\" >0.69</td>\n",
       "      <td id=\"T_bbe5e_row5_col1\" class=\"data row5 col1\" >0.68</td>\n",
       "      <td id=\"T_bbe5e_row5_col2\" class=\"data row5 col2\" >0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbe5e_level0_row6\" class=\"row_heading level0 row6\" rowspan=\"3\">GPT-J (6B)</th>\n",
       "      <th id=\"T_bbe5e_level1_row6\" class=\"row_heading level1 row6\" >manual_gbdt</th>\n",
       "      <td id=\"T_bbe5e_row6_col0\" class=\"data row6 col0\" >0.80</td>\n",
       "      <td id=\"T_bbe5e_row6_col1\" class=\"data row6 col1\" >0.76</td>\n",
       "      <td id=\"T_bbe5e_row6_col2\" class=\"data row6 col2\" >0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbe5e_level1_row7\" class=\"row_heading level1 row7\" >manual_tree</th>\n",
       "      <td id=\"T_bbe5e_row7_col0\" class=\"data row7 col0\" >0.74</td>\n",
       "      <td id=\"T_bbe5e_row7_col1\" class=\"data row7 col1\" >0.72</td>\n",
       "      <td id=\"T_bbe5e_row7_col2\" class=\"data row7 col2\" >0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbe5e_level1_row8\" class=\"row_heading level1 row8\" >single prompt</th>\n",
       "      <td id=\"T_bbe5e_row8_col0\" class=\"data row8 col0\" >0.72</td>\n",
       "      <td id=\"T_bbe5e_row8_col1\" class=\"data row8 col1\" >0.66</td>\n",
       "      <td id=\"T_bbe5e_row8_col2\" class=\"data row8 col2\" >0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb82e14cb10>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_all = means.pivot_table(\n",
    "    index=[\"checkpoint\", \"model_name\"], columns=\"checkpoint_evaluation\", values=metric\n",
    ")\n",
    "vmin = means_all.min().min()\n",
    "vmax = means_all.max().max()\n",
    "means_all.style.format(\"{:.2f}\").background_gradient(cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual_gbdt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_923bf_row0_col0 {\n",
       "  background-color: #7fd34e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_923bf_row0_col1 {\n",
       "  background-color: #20a386;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_923bf_row0_col2 {\n",
       "  background-color: #277f8e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_923bf_row1_col0 {\n",
       "  background-color: #228b8d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_923bf_row1_col1 {\n",
       "  background-color: #fde725;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_923bf_row1_col2 {\n",
       "  background-color: #23888e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_923bf_row2_col0 {\n",
       "  background-color: #26818e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_923bf_row2_col1 {\n",
       "  background-color: #21a585;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_923bf_row2_col2 {\n",
       "  background-color: #dde318;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_923bf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >checkpoint_evaluation</th>\n",
       "      <th id=\"T_923bf_level0_col0\" class=\"col_heading level0 col0\" >GPT-2 (117M)</th>\n",
       "      <th id=\"T_923bf_level0_col1\" class=\"col_heading level0 col1\" >GPT-2 (1.5B)</th>\n",
       "      <th id=\"T_923bf_level0_col2\" class=\"col_heading level0 col2\" >GPT-J (6B)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >checkpoint</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_923bf_level0_row0\" class=\"row_heading level0 row0\" >GPT-2 (117M)</th>\n",
       "      <td id=\"T_923bf_row0_col0\" class=\"data row0 col0\" >0.85</td>\n",
       "      <td id=\"T_923bf_row0_col1\" class=\"data row0 col1\" >0.79</td>\n",
       "      <td id=\"T_923bf_row0_col2\" class=\"data row0 col2\" >0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_923bf_level0_row1\" class=\"row_heading level0 row1\" >GPT-2 (1.5B)</th>\n",
       "      <td id=\"T_923bf_row1_col0\" class=\"data row1 col0\" >0.77</td>\n",
       "      <td id=\"T_923bf_row1_col1\" class=\"data row1 col1\" >0.90</td>\n",
       "      <td id=\"T_923bf_row1_col2\" class=\"data row1 col2\" >0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_923bf_level0_row2\" class=\"row_heading level0 row2\" >GPT-J (6B)</th>\n",
       "      <td id=\"T_923bf_row2_col0\" class=\"data row2 col0\" >0.76</td>\n",
       "      <td id=\"T_923bf_row2_col1\" class=\"data row2 col1\" >0.80</td>\n",
       "      <td id=\"T_923bf_row2_col2\" class=\"data row2 col2\" >0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb82cde25d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual_tree\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9e9fb_row0_col0 {\n",
       "  background-color: #54c568;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9e9fb_row0_col1 {\n",
       "  background-color: #20928c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9e9fb_row0_col2 {\n",
       "  background-color: #34608d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9e9fb_row1_col0 {\n",
       "  background-color: #33628d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9e9fb_row1_col1 {\n",
       "  background-color: #addc30;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9e9fb_row1_col2, #T_9e9fb_row2_col0 {\n",
       "  background-color: #375a8c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9e9fb_row2_col1 {\n",
       "  background-color: #2c728e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9e9fb_row2_col2 {\n",
       "  background-color: #70cf57;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9e9fb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >checkpoint_evaluation</th>\n",
       "      <th id=\"T_9e9fb_level0_col0\" class=\"col_heading level0 col0\" >GPT-2 (117M)</th>\n",
       "      <th id=\"T_9e9fb_level0_col1\" class=\"col_heading level0 col1\" >GPT-2 (1.5B)</th>\n",
       "      <th id=\"T_9e9fb_level0_col2\" class=\"col_heading level0 col2\" >GPT-J (6B)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >checkpoint</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9e9fb_level0_row0\" class=\"row_heading level0 row0\" >GPT-2 (117M)</th>\n",
       "      <td id=\"T_9e9fb_row0_col0\" class=\"data row0 col0\" >0.83</td>\n",
       "      <td id=\"T_9e9fb_row0_col1\" class=\"data row0 col1\" >0.77</td>\n",
       "      <td id=\"T_9e9fb_row0_col2\" class=\"data row0 col2\" >0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e9fb_level0_row1\" class=\"row_heading level0 row1\" >GPT-2 (1.5B)</th>\n",
       "      <td id=\"T_9e9fb_row1_col0\" class=\"data row1 col0\" >0.72</td>\n",
       "      <td id=\"T_9e9fb_row1_col1\" class=\"data row1 col1\" >0.87</td>\n",
       "      <td id=\"T_9e9fb_row1_col2\" class=\"data row1 col2\" >0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e9fb_level0_row2\" class=\"row_heading level0 row2\" >GPT-J (6B)</th>\n",
       "      <td id=\"T_9e9fb_row2_col0\" class=\"data row2 col0\" >0.72</td>\n",
       "      <td id=\"T_9e9fb_row2_col1\" class=\"data row2 col1\" >0.74</td>\n",
       "      <td id=\"T_9e9fb_row2_col2\" class=\"data row2 col2\" >0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb8276057d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single prompt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_74008_row0_col0 {\n",
       "  background-color: #453581;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_74008_row0_col1 {\n",
       "  background-color: #443b84;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_74008_row0_col2 {\n",
       "  background-color: #440154;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_74008_row1_col0 {\n",
       "  background-color: #481c6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_74008_row1_col1 {\n",
       "  background-color: #2e6e8e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_74008_row1_col2 {\n",
       "  background-color: #472e7c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_74008_row2_col0 {\n",
       "  background-color: #481668;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_74008_row2_col1 {\n",
       "  background-color: #34608d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_74008_row2_col2 {\n",
       "  background-color: #3d4d8a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_74008\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >checkpoint_evaluation</th>\n",
       "      <th id=\"T_74008_level0_col0\" class=\"col_heading level0 col0\" >GPT-2 (117M)</th>\n",
       "      <th id=\"T_74008_level0_col1\" class=\"col_heading level0 col1\" >GPT-2 (1.5B)</th>\n",
       "      <th id=\"T_74008_level0_col2\" class=\"col_heading level0 col2\" >GPT-J (6B)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >checkpoint</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_74008_level0_row0\" class=\"row_heading level0 row0\" >GPT-2 (117M)</th>\n",
       "      <td id=\"T_74008_row0_col0\" class=\"data row0 col0\" >0.68</td>\n",
       "      <td id=\"T_74008_row0_col1\" class=\"data row0 col1\" >0.69</td>\n",
       "      <td id=\"T_74008_row0_col2\" class=\"data row0 col2\" >0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74008_level0_row1\" class=\"row_heading level0 row1\" >GPT-2 (1.5B)</th>\n",
       "      <td id=\"T_74008_row1_col0\" class=\"data row1 col0\" >0.66</td>\n",
       "      <td id=\"T_74008_row1_col1\" class=\"data row1 col1\" >0.74</td>\n",
       "      <td id=\"T_74008_row1_col2\" class=\"data row1 col2\" >0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74008_level0_row2\" class=\"row_heading level0 row2\" >GPT-J (6B)</th>\n",
       "      <td id=\"T_74008_row2_col0\" class=\"data row2 col0\" >0.66</td>\n",
       "      <td id=\"T_74008_row2_col1\" class=\"data row2 col1\" >0.72</td>\n",
       "      <td id=\"T_74008_row2_col2\" class=\"data row2 col2\" >0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb82768c250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod_name = \"single prompt\"\n",
    "order = [\"GPT-2 (117M)\", \"GPT-2 (1.5B)\", \"GPT-J (6B)\"]\n",
    "for mod_name in means[\"model_name\"].unique():\n",
    "    print(mod_name)\n",
    "    display(\n",
    "        means[means[\"model_name\"] == mod_name]\n",
    "        .pivot_table(\n",
    "            index=[\"checkpoint\"], columns=\"checkpoint_evaluation\", values=metric\n",
    "        )\n",
    "        .loc[order, order]\n",
    "        .style.format(\"{:.2f}\")\n",
    "        .background_gradient(cmap=\"viridis\", axis=None, vmin=vmin, vmax=vmax)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
